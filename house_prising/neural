#!/usr/bin/ruby

require './../src/RbLearning'
require 'csv'

include Statistics

train = DataManager.new("./input/train.csv")
tests = DataManager.new("./input/test.csv")
train.remove('Id')
tests.remove('Id')
data_y = train.remove('SalePrice')

data_y.map! {|val| val.to_f > 0 ? Math.log(val.to_f) : 0 }


train['LotFrontage'].map! { |val| val == 'NA' ? 0 : val }
tests['LotFrontage'].map! { |val| val == 'NA' ? 0 : val }

train['GarageYrBlt'].map! { |val| val == 'NA' ? 0 : val }
tests['GarageYrBlt'].map! { |val| val == 'NA' ? 0 : val }

train['MasVnrArea'].map! { |val| val == 'NA' ? 0 : val }
tests['MasVnrArea'].map! { |val| val == 'NA' ? 0 : val }

tests.addDumies
train.addDumies

train.labels.each { |l| train.remove(l) if tests[l].nil?  }
tests.labels.each { |l| tests.remove(l) if train[l].nil?  }

lol = true
while lol
	lol = false
	train.labels.each do |l|
		if train.skewness(train[l]).abs > 0.75
			train[l].map! {|val| val.to_f > 0 ? Math.log(val.to_f) : 0 }
			tests[l].map! {|val| val.to_f > 0 ? Math.log(val.to_f) : 0 }
			lol = true
		end
	end
end


train.normalize
tests.normalize

# train.labels.each do |l|
# 	puts l + ": " + corelation(data_y, train[l]).to_s
# end
# exit

x = train.matrixGenerate(tests.labels)

nn = NeuroNet.new

max = data_y.max.to_f
data_y = Matrix.set(data_y.map do |i|
	[i.to_f]
end)

l1 = NetLayer.new(x.size_x, 32, 'reLu', 0.00001)
l2 = NetLayer.new(32, 8, 'reLu', 0.00001)
l3 = NetLayer.new(8, 1, 'reLu', 0.00001)
# l4 = NetLayer.new(16, 8, 'reLu', 0, 0.01)
# l5 = NetLayer.new(8, 4, 'reLu', 0, 0.01)
# l6 = NetLayer.new(4, 1, 'reLu', 0, 0.01)

# layers = [l1]
# layers = [l1, l2]
layers = [l1, l2, l3]
# layers = [l1, l2, l3, l4, l5, l6]

(0...3000).each do |ep|
	batch_x, batch_y = train.batch(data_y, 32)
	it = data_y.size_y / batch_x.size_y
	(0...it).each do |i|
		printF =  i % 1 == 0
		layers = nn.train(layers, batch_x, batch_y, printF)
		puts "epoch: #{ep} iteration: #{i}"
	end
end

(0...1).each do |ep|
	# batch_x, batch_y = train.batch(data_y, 32)
	# it = data_y.size_y / batch_x.size_y
	(0...10000).each do |i|
		printF =  i % 1 == 0
		layers = nn.train(layers, x, data_y, printF)
		puts "epoch: #{ep} iteration: #{i}"
	end
end


m = tests.matrixGenerate(train.labels)

x = Matrix.setVectorizedMatrix(m[0...m.size_y * m.size_x], m.size_y, m.size_x)

zs, pred = nn.feedForward(layers, x)

CSV.open("./res2.csv", "wb") do |csv|
	csv << ['Id', 'SalePrice']
	m = pred.last.get2DArr
	(0...pred.last.size_y).each do |i|
		csv <<  [1461 + i, Math.exp(m[i][0])]
	end
end
