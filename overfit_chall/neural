#!/usr/bin/ruby

require './../src/RbLearning'
require 'csv'

train = DataManager.new("./input/train.csv")
train.remove('id')
data_y = train.remove('target')

nn = NeuroNet.new

train.normalize
m = train.matrix

size = data_y.size
x = Matrix.setVectorizedMatrix(m[0...size * m.size_x], size, m.size_x)

data_y = Matrix.set(data_y.map do |i|
	[i.to_f]
end)

l1 = NetLayer.new(x.size_x, 8, 'sigmoid', 0.005, 30)
l2 = NetLayer.new(8, 1, 'sigmoid', 0.005, 50)
# l3 = NetLayer.new(8, 1, 'reLu', 0.005)

# layers = [l1]
layers = [l1, l2]
# layers = [l1, l2, l3]

(0...3500).each do |ep|
	batch_x, batch_y = train.batch(data_y, 32)
	it = data_y.size_y / batch_x.size_y
	(0...it).each do |i|
		printF =  i % 1 == 0
		layers = nn.train(layers, batch_x, batch_y, printF)
		puts "epoch: #{ep} iteration: #{i}"
	end
end

# l1.dropOut = 0
# l2.dropOut = 0

# (0...1).each do |ep|
# 	(0...50000).each do |i|
# 		printF =  i % 1 == 0
# 		layers = nn.train(layers, x, data_y, printF)
# 		puts "epoch: #{ep} iteration: #{i}"
# 	end
# end


tests = DataManager.new("./input/test.csv")
tests.remove('id')

tests.normalize
m = tests.matrix

x = Matrix.setVectorizedMatrix(m[0...m.size_y * m.size_x], m.size_y, m.size_x)

zs, pred = nn.feedForward(layers, x)
# pred.last.printM(5)

CSV.open("./res1.csv", "wb") do |csv|
	csv << ['id', 'target']
	m = pred.last.get2DArr
	(0...pred.last.size_y).each do |i|
		# puts "#{m[i]}"
		csv <<  [size + i, m[i][0].round]
	end
end
